# Set everything to be logged to file
log4j.rootCategory=WARN, console
#WARN is the log level (includes DEBUG, INFO and ERROR)
#2nd argument is the list of appenders (eg console, file etc..)

# Settings for the console appender
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n

### THE SECTION ABOVE WILL SET THE ROOT LEVEL LOG4J CONFIG (STANDARD)

#Second Log level SPECIFIC to MY CURRENT application
log4j.logger.udemy.spark.examples=INFO, console, file
log4j.additivity.udemy.spark.examples=false

#Settings for File appender since file is included in Application level logs (specific to your application)
log4j.appender.file=org.apache.log4j.FileAppender
log4j.appender.file.File=${spark.yarn.app.container.log.dir}/${logfile.name}.log

#${spark.yarn.app.container.log.dir} & ${logfile.name} is the variable name
#E.g log4j.appender.file.File=logs/udemy_app.log

log4j.appender.file.ImmediateFlush=true
log4j.appender.file.Append=false
log4j.appender.file.MaxFileSize=500MB
log4j.appender.file.MaxBackupIndex=2
log4j.appender.file.layout=org.apache.log4j.PatternLayout
log4j.appender.file.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n

# Recommendations from Spark template
log4j.logger.org.apache.spark.repl.Main=WARN
log4j.logger.org.spark_project.jetty=WARN
log4j.logger.org.spark_project.jetty.util.component.AbstractLifeCycle=ERROR
log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO
log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO
log4j.logger.org.apache.parquet=ERROR
log4j.logger.parquet=ERROR
log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler=FATAL
log4j.logger.org.apache.hadoop.hive.ql.exec.FunctionRegistry=ERROR

# Uncomment to log everything (noisy)
# log4j.rootCategory=DEBUG, console
